{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently having trouble importing urbana so i'm just copying the src-code\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.feature_selection import (\n",
    "    RFE,\n",
    "    SelectKBest,\n",
    "    mutual_info_regression,\n",
    "    f_regression,\n",
    "    SelectPercentile,\n",
    ")\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_validate,\n",
    "    RepeatedKFold,\n",
    "    GridSearchCV,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PowerTransformer, StandardScaler\n",
    "\n",
    "\n",
    "from urbana.features import normaltests\n",
    "from urbana.constants import DIR_REPO, DIR_DATA, RANDOM_STATE\n",
    "from urbana.models.plot_predictions import PredictedAccuracy\n",
    "\n",
    "\n",
    "def LinearModel(YEAR, MONTH, VARIABLE_TO_PREDICT):\n",
    "\n",
    "    mpl.use('Agg')\n",
    "\n",
    "    print(\"Starting with {}-{:02d}\".format(YEAR, MONTH))\n",
    "\n",
    "\n",
    "    OUTPUT_WARNINGS = False\n",
    "    SAVE_FIGS = True\n",
    "    SAVE_MODEL = True\n",
    "\n",
    "    K_EDUCATION = 1\n",
    "    K_AGE = 2\n",
    "    K_NATIONALITY = 2\n",
    "    K_RENT = 1\n",
    "    K_POI = 10\n",
    "\n",
    "\n",
    "    if not OUTPUT_WARNINGS:\n",
    "        import warnings\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "    ALLOWED_YEARS = [2017, 2018, 2023]\n",
    "\n",
    "    if YEAR not in ALLOWED_YEARS:\n",
    "        raise Exception(\"Please select a year within: {}\".format(ALLOWED_YEARS))\n",
    "\n",
    "    if YEAR == 2018 and MONTH == 3:\n",
    "        raise Exception(\n",
    "            \"Month 3 (March) is not available for 2018. Please choose a different month.\"\n",
    "        )\n",
    "\n",
    "\n",
    "    # Create folders to store the data\n",
    "\n",
    "    DIR_VAR = DIR_DATA / \"processed/{}\".format(VARIABLE_TO_PREDICT)\n",
    "    DIR_MONTH = DIR_VAR / \"{}_{:02d}\".format(YEAR, MONTH)\n",
    "    DIR_LINEAR = DIR_MONTH / \"01_linear\"\n",
    "\n",
    "    if SAVE_FIGS or SAVE_MODEL:\n",
    "        folder_list = [DIR_VAR, DIR_MONTH, DIR_LINEAR, DIR_VAR / \"01_linear\"]\n",
    "\n",
    "        import os\n",
    "\n",
    "        for folder in folder_list:\n",
    "            if not os.path.exists(folder):\n",
    "                os.makedirs(folder)\n",
    "\n",
    "\n",
    "    PATH_TO_FILE = DIR_DATA / \"interim/sections_{}_{:02d}.csv\".format(YEAR, MONTH)\n",
    "    if os.path.isfile(PATH_TO_FILE) is False:\n",
    "        raise Exception(\n",
    "            'Please run first the notebook \"00acquisition.ipynb\" with the same date and \"SAVE_DATA\" set to True'\n",
    "        )\n",
    "\n",
    "    np.random.seed(RANDOM_STATE)\n",
    "\n",
    "    sect = pd.read_csv(\n",
    "        DIR_DATA / \"interim/sections_{}_{:02d}.csv\".format(YEAR, MONTH),\n",
    "    )\n",
    "\n",
    "    sect.set_index(\"Tag\", inplace=True)\n",
    "\n",
    "    sect.drop([\"N_district\", \"N_neighbourhood\", \"N_section\"], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "    y = sect[VARIABLE_TO_PREDICT]\n",
    "\n",
    "    X = sect.drop(\n",
    "        [\"Airbnb_Number\", \"Airbnb_Price\", \"Airbnb_Price_Person\", \"Airbnb_Location_Score\"],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    geo_info = gpd.read_file(DIR_DATA / \"interim/sections_geo.json\")\n",
    "\n",
    "    geo_info.set_index(\"Tag\", inplace=True)\n",
    "\n",
    "    geo_info[VARIABLE_TO_PREDICT] = sect[VARIABLE_TO_PREDICT]\n",
    "\n",
    "    #print(\"Area with maximum value: \" + str(geo_info[VARIABLE_TO_PREDICT].idxmax()))\n",
    "\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "    geo_info.plot(\n",
    "        ax=ax,\n",
    "        column=VARIABLE_TO_PREDICT,\n",
    "        legend=True,\n",
    "        figsize=(20, 20),\n",
    "        legend_kwds={\"shrink\": 0.7},\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Target variable: \" + str(VARIABLE_TO_PREDICT), fontsize=20, y=1.01)\n",
    "\n",
    "    if SAVE_FIGS:\n",
    "        plt.savefig(DIR_LINEAR / \"target_variable.svg\", format=\"svg\")\n",
    "\n",
    "\n",
    "    # Check which variables are already normal\n",
    "    normality_test = normaltests.get_normaltest_df(X.T)\n",
    "\n",
    "    pt = PowerTransformer()\n",
    "    preprocessor = Pipeline(steps=[(\"imputer\", KNNImputer()), (\"pt\", pt)])\n",
    "\n",
    "    X_Education = X.filter(regex=\"^Education\")\n",
    "\n",
    "    kbest_Education = SelectKBest(f_regression, k=K_EDUCATION).fit(\n",
    "        preprocessor.fit_transform(X_Education),\n",
    "        pt.fit_transform(y.values.reshape(-1, 1)),\n",
    "    )\n",
    "\n",
    "    education_cols = kbest_Education.get_support(indices=True)\n",
    "    X_Education_chosen = X_Education.columns[education_cols]\n",
    "    #X_Education_chosen\n",
    "\n",
    "\n",
    "\n",
    "    X_Age = X.filter(regex=\"^Percentage_Age_\")\n",
    "    print(X_Age)\n",
    "    kbest_Age = SelectKBest(f_regression, k=K_AGE).fit(\n",
    "        preprocessor.fit_transform(X_Age),\n",
    "        pt.fit_transform(y.values.reshape(-1, 1)),\n",
    "    )\n",
    "\n",
    "    age_cols = kbest_Age.get_support(indices=True)\n",
    "    X_Age_chosen = X_Age.columns[age_cols]\n",
    "    #X_Age_chosen\n",
    "\n",
    "\n",
    "\n",
    "    X_Nationality = X.filter(regex=\"^Nationality_\")\n",
    "    X_Nationality.drop([\"Nationality_Spain\"], axis=1, inplace=True)\n",
    "    kbest_Nationality = SelectKBest(f_regression, k=K_NATIONALITY).fit(\n",
    "        preprocessor.fit_transform(X_Nationality),\n",
    "        pt.fit_transform(y.values.reshape(-1, 1)),\n",
    "    )\n",
    "\n",
    "    nationality_cols = kbest_Nationality.get_support(indices=True)\n",
    "    X_Nationality_chosen = X_Nationality.columns[nationality_cols]\n",
    "    #X_Nationality_chosen\n",
    "\n",
    "    if YEAR >= 2015 and YEAR <= 2018:\n",
    "\n",
    "        X_Rent = X.filter(regex=\"^Rent_\")\n",
    "        kbest_Rent = SelectKBest(f_regression, k=K_RENT).fit(\n",
    "            preprocessor.fit_transform(X_Rent),\n",
    "            pt.fit_transform(y.values.reshape(-1, 1)),\n",
    "        )\n",
    "\n",
    "        rent_cols = kbest_Rent.get_support(indices=True)\n",
    "        X_Rent_chosen = X_Rent.columns[rent_cols]\n",
    "        #X_Rent_chosen\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_POI = X.filter(regex=\"^POI\")\n",
    "\n",
    "    kbest_POI = SelectKBest(f_regression, k=K_POI).fit(\n",
    "        preprocessor.fit_transform(X_POI),\n",
    "        pt.fit_transform(y.values.reshape(-1, 1)),\n",
    "    )\n",
    "\n",
    "    POI_cols = kbest_POI.get_support(indices=True)\n",
    "    X_POI_chosen = X_POI.columns[POI_cols]\n",
    "    #X_POI_chosen\n",
    "\n",
    "\n",
    "    if YEAR >= 2015 and YEAR <= 2018:\n",
    "        X.drop(np.setdiff1d(X_Rent.columns, X_Rent_chosen), axis=1, inplace=True)\n",
    "\n",
    "    X.drop(np.setdiff1d(X_Age.columns, X_Age_chosen), axis=1, inplace=True)\n",
    "\n",
    "    X.drop(np.setdiff1d(X_Nationality.columns, X_Nationality_chosen), axis=1, inplace=True)\n",
    "\n",
    "    X.drop(np.setdiff1d(X_Education.columns, X_Education_chosen), axis=1, inplace=True)\n",
    "\n",
    "    X.drop(np.setdiff1d(X_POI.columns, X_POI_chosen), axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # ## Feature Selection Pipeline\n",
    "\n",
    "    # In order to perform a feature selection, we will use *RFE* (Recursive Feature Elimination).\n",
    "    # \n",
    "    # The number of variables to use will be a hyper-paramater that will be tuned with a GridSearch using RMSE as the metric.\n",
    "    # \n",
    "    # The target feature will also be transformed with a PowerTransfomrer, by applying the *TransformedTargetRegressor*.\n",
    "\n",
    "\n",
    "    # Define the regressor to use\n",
    "    myRegressor = LinearRegression()\n",
    "\n",
    "    # Define a pipeline with the preprocessing, feature selection (RFE) and regressor\n",
    "    pipe_rfe = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"rfe\", RFE(estimator=myRegressor)),\n",
    "            (\"regressor\", myRegressor),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Define the param space for hyper-parameter tunning (in this case, the number of features to keep with RFE)\n",
    "    param_grid_rfe = [{\"rfe__n_features_to_select\": np.arange(6, 15, 1)}]\n",
    "\n",
    "    search_rfe = GridSearchCV(\n",
    "        pipe_rfe, param_grid_rfe, scoring=\"neg_root_mean_squared_error\", n_jobs=-1\n",
    "    )\n",
    "\n",
    "\n",
    "    model = TransformedTargetRegressor(regressor=search_rfe, transformer=PowerTransformer())\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"Best Model:\")\n",
    "    #print(\n",
    "    #    \"Number of features: \"\n",
    "    #    + str(model.regressor_.best_params_[\"rfe__n_features_to_select\"])\n",
    "    #)\n",
    "    #print(\"\\nList of features:\")\n",
    "    cols_rfe = model.regressor_.best_estimator_.named_steps[\"rfe\"].get_support(indices=True)\n",
    "    #print(X.columns[cols_rfe])\n",
    "\n",
    "\n",
    "\n",
    "    score_features = -model.regressor_.cv_results_[\"mean_test_score\"]\n",
    "    n_features = []\n",
    "    for i in model.regressor_.cv_results_[\"params\"]:\n",
    "        n_features.append(i[\"rfe__n_features_to_select\"])\n",
    "\n",
    "    id_min_score = score_features.argmin()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 10))\n",
    "    plt.plot(n_features, score_features, marker=\"o\")\n",
    "    plt.axvline(x=n_features[id_min_score], color=\".5\")\n",
    "\n",
    "    ax.set_xlabel(\"Number of features\", fontsize=15)\n",
    "    ax.set_ylabel(\"Median Absolute Error\", fontsize=15)\n",
    "    ax.set_xticks(np.arange(min(n_features), max(n_features) + 1))\n",
    "    ax.set_title(\"Score by number of features\", fontsize=20, y=1.01)\n",
    "\n",
    "    if SAVE_FIGS:\n",
    "        plt.savefig(DIR_LINEAR / \"selection_rmse.svg\", format=\"svg\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    y_pred_rfe = model.predict(X).round()\n",
    "    pa_rfe = PredictedAccuracy(y, y_pred_rfe)\n",
    "    pa_rfe.plot_scatter(save_fig=SAVE_FIGS, root_name=DIR_LINEAR / \"model\"), y=1.01)\n",
    "\n",
    "\n",
    "    if SAVE_FIGS:\n",
    "        plt.savefig(DIR_LINEAR / \"relative_errors.svg\", format=\"svg\")\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "    if SAVE_MODEL:\n",
    "        geo_info[[\"Chosen_Error\"]].to_csv(DIR_LINEAR / \"relative_errors.csv\")\n",
    "        df_predictions = pd.DataFrame(y_pred_rfe, index=geo_info.index, columns=[\"Predictions\"])\n",
    "        df_predictions.to_csv(DIR_LINEAR / \"predictions.csv\")  \n",
    "        df_predictions.to_csv(DIR_VAR / \"01_linear/predictions_{}_{:02d}.csv\".format(YEAR, MONTH))  \n",
    "\n",
    "    # from yellowbrick.regressor.residuals import residuals_plot\n",
    "\n",
    "    # residuals_plot(\n",
    "    #     model, X_train, y_train, X_test, y_test, hist=False, qqplot=True, is_fitted=True\n",
    "    # )\n",
    "\n",
    "    # residuals_plot(\n",
    "    #     model, X_train, y_train, X_test, y_test, hist=True, qqplot=False, is_fitted=True\n",
    "    # )\n",
    "\n",
    "\n",
    "    pw = PowerTransformer()\n",
    "    pw.fit(y.values.reshape(-1, 1))\n",
    "\n",
    "    ####################Tranform y_hat####################\n",
    "    y_pred_transformed = model.predict(X)\n",
    "    y_pred_transformed = pw.transform(y_pred_transformed.reshape(-1, 1)).flatten()\n",
    "\n",
    "    ####################Trasform y####################\n",
    "    # y_test_transformed = pd.Series(pw.transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "    y_transformed = pd.Series(pw.transform(y.values.reshape(-1, 1)).flatten())\n",
    "    y_transformed.name = \"Transformed Airbnb_Number\"\n",
    "\n",
    "    pa_trans = PredictedAccuracy(y_transformed, y_pred_transformed)\n",
    "    pa_trans.plot_scatter(\n",
    "\n",
    "    ####################Tranform y_hat####################\n",
    "    y_pred_transformed = model.predict(X)\n",
    "    y_pred_transformed = pw.transform(y_pred_transformed.reshape(-1, 1)).flatten()\n",
    "\n",
    "    ####################Trasform y####################\n",
    "    # y_test_transformed = pd.Series(pw.transform(y_test.values.reshape(-1, 1)).flatten())\n",
    "    y_transformed = pd.Series(pw.transform(y.values.reshape(-1, 1)).flatten())\n",
    "    y_transformed.name = \"Transformed Airbnb_Number\"\n",
    "\n",
    "    pa_trans = PredictedAccuracy(y_transformed, y_pred_transformed)\n",
    "    pa_trans.plot_scatter(\n",
    "        save_fig=SAVE_FIGS,\n",
    "        root_name=DIR_LINEAR / \"transformed_model\",\n",
    "    )\n",
    "    pa_trans.plot_errors(\n",
    "        save_fig=SAVE_FIGS,\n",
    "        root_name=DIR_LINEAR / \"transformed_model\",\n",
    "    )\n",
    "    del pa_trans\n",
    "\n",
    "\n",
    "    # # Sensitivity Analysis\n",
    "\n",
    "\n",
    "    X_rfe = X.iloc[:, cols_rfe]\n",
    "\n",
    "    pipe_sens = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"regressor\", myRegressor)])\n",
    "\n",
    "    model_sens = TransformedTargetRegressor(\n",
    "        regressor=pipe_sens, transformer=PowerTransformer()\n",
    "    )\n",
    "\n",
    "    model_sens.fit(X_rfe, y)\n",
    "\n",
    "\n",
    "\n",
    "    cv_rfe = cross_validate(\n",
    "        model_sens,\n",
    "        X_rfe,\n",
    "        y,\n",
    "        cv=RepeatedKFold(n_splits=5, n_repeats=5),\n",
    "        scoring=[\"neg_root_mean_squared_error\"],\n",
    "        return_estimator=True,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    coefs_rfe = pd.DataFrame(\n",
    "        [est.regressor_.named_steps[\"regressor\"].coef_ for est in cv_rfe[\"estimator\"]],\n",
    "        columns=X_rfe.columns,\n",
    "    )\n",
    "\n",
    "\n",
    "    coefs_rfe[\"Intercept\"] = pd.Series(\n",
    "        [est.regressor_.named_steps[\"regressor\"].intercept_ for est in cv_rfe[\"estimator\"]]\n",
    "    )\n",
    "\n",
    "    medians_rfe = coefs_rfe.drop([\"Intercept\"], axis=1).median()\n",
    "    medians_rfe = medians_rfe.reindex(medians_rfe.abs().sort_values(ascending=False).index)\n",
    "    medians_rfe = pd.concat(\n",
    "        [medians_rfe, pd.Series({\"Intercept\": None}, index=[\"Intercept\"])]\n",
    "    )\n",
    "    coefs_rfe = coefs_rfe[medians_rfe.index]\n",
    "\n",
    "    limit_value = (\n",
    "        max(abs(coefs_rfe.to_numpy().min()), abs(coefs_rfe.to_numpy().max())) * 1.05\n",
    "    )\n",
    "\n",
    "    print(coefs_rfe)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "    sns.stripplot(ax=ax, data=coefs_rfe, orient=\"h\", color=\"k\", alpha=0.5)\n",
    "    sns.boxplot(ax=ax, data=coefs_rfe, orient=\"h\", color=\"cyan\", saturation=0.5)\n",
    "    plt.axvline(x=0, color=\"red\")\n",
    "\n",
    "    plt.figtext(0.51, 0.9, \"Linear Model: Coefficient robustness\", fontsize=20, ha=\"center\")\n",
    "    plt.figtext(\n",
    "        0.51,\n",
    "        0.885,\n",
    "        \"{}-{:02d}\".format(YEAR, MONTH),\n",
    "        fontsize=18,\n",
    "        ha=\"center\",\n",
    "    )\n",
    "    ax.set_xlim(-limit_value, limit_value)\n",
    "    ax.set_xlabel(\"Coefficient value\", fontsize=15)\n",
    "\n",
    "    if SAVE_FIGS:\n",
    "        plt.savefig(DIR_LINEAR / \"sensitivity.svg\", format=\"svg\")\n",
    "        plt.savefig(DIR_VAR / \"01_linear/sensitivity_{}_{:02d}.svg\".format(YEAR, MONTH), format=\"svg\")\n",
    "        \n",
    "\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if SAVE_MODEL:\n",
    "        coefs_rfe.to_csv(DIR_LINEAR / \"coefficients.csv\")\n",
    "        coefs_rfe.to_csv(DIR_VAR / \"01_linear/coefficients_{}_{:02d}.csv\".format(YEAR, MONTH))\n",
    "\n",
    "    print(\"Done with {}-{:02d}\".format(YEAR, MONTH))\n",
    "    print(\"##################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with 2023-12\n",
      "line 223\n",
      "        Percentage_Age_0_14  Percentage_Age_15_24  Percentage_Age_25_39  \\\n",
      "Tag                                                                       \n",
      "01_001             0.123172              0.087760              0.326405   \n",
      "01_002             0.101376              0.126720              0.356264   \n",
      "01_003             0.200466              0.130637              0.268548   \n",
      "01_004             0.122317              0.111414              0.336627   \n",
      "01_005             0.118053              0.112452              0.316674   \n",
      "...                     ...                   ...                   ...   \n",
      "10_143             0.122778              0.110556              0.201111   \n",
      "10_234             0.091419              0.087493              0.199103   \n",
      "10_235             0.105837              0.066148              0.167315   \n",
      "10_236             0.091536              0.067712              0.183699   \n",
      "10_237             0.111720              0.101862              0.193866   \n",
      "\n",
      "        Percentage_Age_40_64  Percentage_Age_65_Plus  \n",
      "Tag                                                   \n",
      "01_001              0.318707                0.143957  \n",
      "01_002              0.281680                0.133961  \n",
      "01_003              0.291824                0.108525  \n",
      "01_004              0.329472                0.100170  \n",
      "01_005              0.326583                0.126239  \n",
      "...                      ...                     ...  \n",
      "10_143              0.350556                0.215000  \n",
      "10_234              0.343242                0.278744  \n",
      "10_235              0.367315                0.293385  \n",
      "10_236              0.318495                0.338558  \n",
      "10_237              0.363636                0.228916  \n",
      "\n",
      "[1068 rows x 5 columns]\n",
      "    POI_Education     Nicaragua  Rent_Area_Flats   POI_Culture  \\\n",
      "0             1.0  1.786765e-16     1.526557e-16  1.110223e-16   \n",
      "1             1.0  5.030698e-17    -3.920475e-16  2.775558e-16   \n",
      "2             1.0  1.769418e-16     7.008283e-16 -2.775558e-17   \n",
      "3             1.0 -3.625572e-16     5.898060e-17 -8.326673e-17   \n",
      "4             1.0  2.168404e-16     6.245005e-17 -2.775558e-17   \n",
      "5             1.0 -4.978656e-16     3.642919e-16  1.110223e-16   \n",
      "6             1.0  7.285839e-17     1.942890e-16 -4.718448e-16   \n",
      "7             1.0 -1.561251e-16    -2.463307e-16  2.498002e-16   \n",
      "8             1.0 -3.538836e-16    -2.602085e-16 -4.163336e-16   \n",
      "9             1.0 -2.706169e-16     1.110223e-16 -2.775558e-16   \n",
      "10            1.0 -1.006140e-16    -6.245005e-17 -5.551115e-17   \n",
      "11            1.0  8.500145e-16    -4.510281e-16  5.551115e-16   \n",
      "12            1.0 -4.371503e-16     1.030426e-15 -1.110223e-16   \n",
      "13            1.0  6.140921e-16    -1.387779e-16  2.498002e-16   \n",
      "14            1.0 -3.217912e-16     2.775558e-16 -1.387779e-16   \n",
      "15            1.0 -5.568462e-16     4.787837e-16  8.326673e-17   \n",
      "16            1.0 -2.532696e-16     3.226586e-16 -1.665335e-16   \n",
      "17            1.0 -1.387779e-17    -2.046974e-16  4.440892e-16   \n",
      "18            1.0  2.029626e-16    -5.551115e-17 -5.273559e-16   \n",
      "19            1.0  2.307182e-16    -2.498002e-16  8.326673e-17   \n",
      "20            1.0 -3.521489e-16     1.595946e-16 -1.665335e-16   \n",
      "21            1.0  6.938894e-18    -5.204170e-17 -1.110223e-16   \n",
      "22            1.0 -5.273559e-16     4.753142e-16  0.000000e+00   \n",
      "23            1.0  1.647987e-16     1.838807e-16 -2.220446e-16   \n",
      "24            1.0 -2.671474e-16    -3.018419e-16  2.498002e-16   \n",
      "\n",
      "    Rent_Price_Meter_Flats  Distance_Center     Intercept  \n",
      "0            -3.191891e-16     8.390899e-17 -2.378909e-30  \n",
      "1             4.579670e-16     3.424403e-16  2.465190e-32  \n",
      "2            -1.249001e-16     2.234602e-17  1.321342e-29  \n",
      "3             5.551115e-17     2.945955e-16 -6.902533e-31  \n",
      "4             4.163336e-17     5.127277e-17  2.218671e-30  \n",
      "5            -8.326673e-17    -1.212431e-16 -6.606710e-30  \n",
      "6             6.938894e-17    -1.509782e-16 -2.816480e-30  \n",
      "7            -2.498002e-16    -3.311098e-17  2.372746e-30  \n",
      "8            -2.359224e-16     2.984063e-16 -3.617667e-30  \n",
      "9            -2.359224e-16    -3.991692e-17 -9.614242e-31  \n",
      "10           -4.163336e-17     1.249529e-16 -8.884605e-31  \n",
      "11            4.579670e-16    -1.033093e-15 -3.475918e-30  \n",
      "12            2.775558e-17     3.395817e-16 -5.250855e-30  \n",
      "13            2.775558e-17    -2.956866e-16  2.514494e-30  \n",
      "14            2.775558e-17     1.575480e-16  1.318877e-30  \n",
      "15            2.914335e-16     3.376041e-18 -4.264779e-30  \n",
      "16           -1.804112e-16    -1.472918e-16  9.934717e-30  \n",
      "17            1.942890e-16    -4.001335e-17 -7.321615e-30  \n",
      "18            2.914335e-16     1.427122e-17  2.542228e-31  \n",
      "19            2.636780e-16    -3.413521e-16  5.028988e-30  \n",
      "20           -1.387779e-16    -1.821930e-16 -2.662406e-30  \n",
      "21            2.914335e-16    -9.256401e-17  1.867382e-30  \n",
      "22           -1.387779e-17     1.749060e-16  3.500570e-30  \n",
      "23           -9.714451e-17     3.000898e-17 -2.597694e-30  \n",
      "24            1.665335e-16     5.172486e-16  3.845697e-30  \n",
      "Done with 2023-12\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "LinearModel(2023, 12, \"POI_Education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running with model with POI_Daily_Food\n",
      "Starting with 2023-12\n",
      "line 223\n",
      "        Percentage_Age_0_14  Percentage_Age_15_24  Percentage_Age_25_39  \\\n",
      "Tag                                                                       \n",
      "01_001             0.123172              0.087760              0.326405   \n",
      "01_002             0.101376              0.126720              0.356264   \n",
      "01_003             0.200466              0.130637              0.268548   \n",
      "01_004             0.122317              0.111414              0.336627   \n",
      "01_005             0.118053              0.112452              0.316674   \n",
      "...                     ...                   ...                   ...   \n",
      "10_143             0.122778              0.110556              0.201111   \n",
      "10_234             0.091419              0.087493              0.199103   \n",
      "10_235             0.105837              0.066148              0.167315   \n",
      "10_236             0.091536              0.067712              0.183699   \n",
      "10_237             0.111720              0.101862              0.193866   \n",
      "\n",
      "        Percentage_Age_40_64  Percentage_Age_65_Plus  \n",
      "Tag                                                   \n",
      "01_001              0.318707                0.143957  \n",
      "01_002              0.281680                0.133961  \n",
      "01_003              0.291824                0.108525  \n",
      "01_004              0.329472                0.100170  \n",
      "01_005              0.326583                0.126239  \n",
      "...                      ...                     ...  \n",
      "10_143              0.350556                0.215000  \n",
      "10_234              0.343242                0.278744  \n",
      "10_235              0.367315                0.293385  \n",
      "10_236              0.318495                0.338558  \n",
      "10_237              0.363636                0.228916  \n",
      "\n",
      "[1068 rows x 5 columns]\n",
      "    POI_Esthetics  POI_Clothing  Education_University  POI_Restaurants_Hotels  \\\n",
      "0        0.200468      0.215045             -0.190326                0.176726   \n",
      "1        0.230366      0.228107             -0.220636                0.169615   \n",
      "2        0.213277      0.201915             -0.167673                0.171621   \n",
      "3        0.211982      0.222770             -0.208944                0.147942   \n",
      "4        0.219967      0.188823             -0.140989                0.172472   \n",
      "5        0.202702      0.199315             -0.153036                0.145498   \n",
      "6        0.221588      0.206506             -0.187607                0.177714   \n",
      "7        0.217584      0.230596             -0.207636                0.171425   \n",
      "8        0.223756      0.203030             -0.203155                0.158561   \n",
      "9        0.212400      0.222281             -0.182195                0.186287   \n",
      "10       0.238464      0.228654             -0.199077                0.154353   \n",
      "11       0.206529      0.215681             -0.191017                0.172118   \n",
      "12       0.183933      0.241281             -0.163335                0.133394   \n",
      "13       0.219582      0.180412             -0.168406                0.226149   \n",
      "14       0.222327      0.201184             -0.215139                0.153710   \n",
      "15       0.195201      0.228526             -0.185469                0.154773   \n",
      "16       0.207424      0.205939             -0.168694                0.170894   \n",
      "17       0.214113      0.209220             -0.213374                0.196084   \n",
      "18       0.238053      0.211177             -0.192291                0.166542   \n",
      "19       0.216806      0.206418             -0.181932                0.156638   \n",
      "20       0.227495      0.212946             -0.206169                0.180487   \n",
      "21       0.203438      0.220939             -0.203206                0.165344   \n",
      "22       0.204129      0.199687             -0.163047                0.191921   \n",
      "23       0.208062      0.204807             -0.147784                0.187745   \n",
      "24       0.228397      0.220337             -0.209017                0.115667   \n",
      "\n",
      "    POI_Daily_Others  Nationality_Spain  Nationality_Italy  Rent_Number_Flats  \\\n",
      "0           0.130398           0.069245           0.041393           0.087813   \n",
      "1           0.108250           0.156332           0.140436           0.080027   \n",
      "2           0.119291           0.082076           0.072991           0.106235   \n",
      "3           0.115933           0.161983           0.156995           0.091029   \n",
      "4           0.152353           0.075171           0.056908           0.079556   \n",
      "5           0.147864           0.069714           0.031248           0.096225   \n",
      "6           0.114934           0.146691           0.134145           0.091793   \n",
      "7           0.123895           0.179114           0.122515           0.084288   \n",
      "8           0.122936           0.079294           0.116889           0.077265   \n",
      "9           0.115694           0.074381           0.060161           0.098163   \n",
      "10          0.097213           0.100383           0.100268           0.091475   \n",
      "11          0.115106           0.120972           0.090808           0.095400   \n",
      "12          0.153758           0.057688           0.045001           0.078011   \n",
      "13          0.139938           0.120230           0.087595           0.097914   \n",
      "14          0.121310           0.148226           0.141455           0.086431   \n",
      "15          0.135811           0.127012           0.095250           0.096610   \n",
      "16          0.138694           0.099350           0.075269           0.080652   \n",
      "17          0.097219           0.095689           0.119870           0.104508   \n",
      "18          0.140539           0.117106           0.071504           0.059427   \n",
      "19          0.114557           0.112408           0.107224           0.105728   \n",
      "20          0.108062           0.107718           0.109104           0.078221   \n",
      "21          0.122405           0.060950           0.073281           0.083464   \n",
      "22          0.123299           0.097861           0.100300           0.093294   \n",
      "23          0.127182           0.098570           0.055137           0.094456   \n",
      "24          0.143479           0.166768           0.126533           0.097183   \n",
      "\n",
      "    Percentage_Age_25_39  POI_Souvenirs_Thrift_Store  POI_House_Equipment  \\\n",
      "0               0.060167                    0.076378             0.078934   \n",
      "1               0.093927                    0.053027             0.077806   \n",
      "2               0.069253                    0.081315             0.075488   \n",
      "3               0.113483                    0.081499             0.084350   \n",
      "4               0.071524                    0.085471             0.063661   \n",
      "5               0.073503                    0.098916             0.075512   \n",
      "6               0.095085                    0.063709             0.073382   \n",
      "7               0.123547                    0.058669             0.062303   \n",
      "8               0.041073                    0.073488             0.105659   \n",
      "9               0.077646                    0.079103             0.070522   \n",
      "10              0.067704                    0.076288             0.090228   \n",
      "11              0.097184                    0.072822             0.074016   \n",
      "12              0.061590                    0.068974             0.085718   \n",
      "13              0.073614                    0.074951             0.056193   \n",
      "14              0.103750                    0.082380             0.080355   \n",
      "15              0.081302                    0.091224             0.064536   \n",
      "16              0.090562                    0.067462             0.081377   \n",
      "17              0.049790                    0.055552             0.095240   \n",
      "18              0.113235                    0.081003             0.067558   \n",
      "19              0.071954                    0.077664             0.077549   \n",
      "20              0.042967                    0.086936             0.071168   \n",
      "21              0.072493                    0.053579             0.067017   \n",
      "22              0.084325                    0.094216             0.071307   \n",
      "23              0.081896                    0.062455             0.085551   \n",
      "24              0.114137                    0.079954             0.091703   \n",
      "\n",
      "    POI_Finances  Rent_Price_Meter_Flats  Household     Intercept  \n",
      "0       0.071686               -0.023932   0.024471  1.542970e-15  \n",
      "1       0.083497               -0.041926   0.036565 -6.106549e-15  \n",
      "2       0.073188               -0.042421   0.032011  1.366974e-15  \n",
      "3       0.056035               -0.056906   0.059393  1.242318e-15  \n",
      "4       0.056849               -0.040069   0.039111 -5.164582e-15  \n",
      "5       0.067196               -0.027762   0.004390 -2.065650e-17  \n",
      "6       0.065336               -0.047364   0.046439  6.894923e-15  \n",
      "7       0.095098               -0.026087   0.048325 -8.979042e-15  \n",
      "8       0.067318               -0.040727   0.052094 -1.212456e-14  \n",
      "9       0.037165               -0.059018   0.045553 -1.677039e-15  \n",
      "10      0.049366               -0.028176   0.057296  7.146046e-14  \n",
      "11      0.085782               -0.044881   0.048477  3.389979e-15  \n",
      "12      0.068267               -0.044349   0.007583  8.314707e-16  \n",
      "13      0.051832               -0.052571   0.036859 -4.352840e-15  \n",
      "14      0.080626               -0.026970   0.042329 -2.144574e-15  \n",
      "15      0.067101               -0.039005   0.049208  4.146083e-15  \n",
      "16      0.055803               -0.046711   0.030601 -4.508016e-15  \n",
      "17      0.071008               -0.048709   0.040387 -5.899345e-15  \n",
      "18      0.073404               -0.011506   0.046715 -7.845492e-15  \n",
      "19      0.069084               -0.050195   0.031316 -5.920460e-15  \n",
      "20      0.086918               -0.023514   0.024571 -8.676618e-15  \n",
      "21      0.091454               -0.044718   0.024132  6.819548e-15  \n",
      "22      0.050261               -0.054064   0.063248 -9.672929e-17  \n",
      "23      0.060535               -0.051974   0.024067 -3.613881e-15  \n",
      "24      0.044884               -0.030167   0.055351 -7.339653e-15  \n",
      "Done with 2023-12\n",
      "##################################\n"
     ]
    }
   ],
   "source": [
    "YEAR, MONTH = 2023, 12\n",
    "path_to_file = DIR_DATA / \"interim/sections_{}_{:02d}.csv\".format(YEAR, MONTH)\n",
    "df = pd.read_csv(path_to_file)\n",
    "all_features = df.columns\n",
    "# skipping section coding and nationality features\n",
    "independent_features = all_features[5:38]\n",
    "nan_columns = df[independent_features].apply(lambda col: col.isna().values.any())\n",
    "features_to_use = independent_features[~nan_columns]\n",
    "\n",
    "for feature in features_to_use[:1]:\n",
    "    print(f'running with model with {feature}')\n",
    "    LinearModel(YEAR, MONTH, feature)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ver relaciones interesantes:\n",
    "- airbnb nunber: distance-center, poi restaurants/hotels, nationality UK, edad 25-39\n",
    "- edades0-14: distance-center, edad25-39, education-none, household?\n",
    "- edades25-39: espagnoles, age65+, distance-center\n",
    "- souvenirs_stores: distance-center, rent-price\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
